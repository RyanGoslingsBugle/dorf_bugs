{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty straightforward text generation task, using a fine-tuned version of the GPT-2 language model to quickly come up with some amusing texts that look relatively close to actual bug reports, albeit a little skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do yourself a favour and run this on a GPU. I haven't timed it CPU-only, since I think I'll probably need my computer in the next few days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells scrape the text of various bug reports from the Dwarf Fortress tracker... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bugs_page(pageno):\n",
    "    r = requests.get(f'https://www.bay12games.com/dwarves/mantisbt/view_all_bug_page.php?page_number={pageno}')\n",
    "    if r.status_code == 200:\n",
    "        return r.text\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bug_text(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    tds = soup.find_all('td', class_='left')\n",
    "    return [td.text.strip() for td in tds[:-1] if len(td.text) > 5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fire them into a text file, separated by newlines, for use in training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 215): #TODO: get rid of magic number\n",
    "    text = get_bugs_page(i)\n",
    "    bugs = extract_bug_text(text)\n",
    "    with open('bugs.txt', 'a', encoding='utf-8') as outfile:\n",
    "        for bug in bugs:\n",
    "            outfile.write(f'{bug}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the 3.55 million parameter gpt-2 model here, which clocks in at about 1.5GB before fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"355M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've set the fine-tuning to start from scratch every time, without restoring from a previous model run. If you want to restore, just remove the restore_from param. It will also give a sample output every 200 training steps. I'm only training for 1,000 steps here, but you could probably get better results with more training - although there's always the risk of creating spurious connections from training with a restricted task dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rich\\anaconda3\\lib\\site-packages\\gpt_2_simple\\src\\sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Rich\\anaconda3\\lib\\site-packages\\gpt_2_simple\\src\\memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
      "Instructions for updating:\n",
      "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
      "Loading checkpoint models\\355M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models\\355M\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 134144 tokens\n",
      "Training...\n",
      "[1 | 9.70] loss=4.59 avg=4.59\n",
      "[2 | 10.72] loss=4.79 avg=4.69\n",
      "[3 | 11.73] loss=4.70 avg=4.69\n",
      "[4 | 12.75] loss=4.59 avg=4.67\n",
      "[5 | 13.77] loss=4.47 avg=4.63\n",
      "[6 | 14.78] loss=4.67 avg=4.64\n",
      "[7 | 15.80] loss=4.47 avg=4.61\n",
      "[8 | 16.81] loss=4.48 avg=4.59\n",
      "[9 | 17.82] loss=4.70 avg=4.61\n",
      "[10 | 18.84] loss=4.58 avg=4.60\n",
      "[11 | 19.87] loss=4.58 avg=4.60\n",
      "[12 | 20.91] loss=4.75 avg=4.61\n",
      "[13 | 21.92] loss=4.48 avg=4.60\n",
      "[14 | 22.96] loss=4.43 avg=4.59\n",
      "[15 | 23.99] loss=4.49 avg=4.58\n",
      "[16 | 25.04] loss=4.19 avg=4.56\n",
      "[17 | 26.08] loss=4.52 avg=4.55\n",
      "[18 | 27.12] loss=4.54 avg=4.55\n",
      "[19 | 28.14] loss=4.24 avg=4.54\n",
      "[20 | 29.16] loss=4.65 avg=4.54\n",
      "[21 | 30.18] loss=4.43 avg=4.54\n",
      "[22 | 31.21] loss=4.44 avg=4.53\n",
      "[23 | 32.25] loss=4.67 avg=4.54\n",
      "[24 | 33.29] loss=4.17 avg=4.52\n",
      "[25 | 34.31] loss=4.47 avg=4.52\n",
      "[26 | 35.36] loss=4.28 avg=4.51\n",
      "[27 | 36.44] loss=4.51 avg=4.51\n",
      "[28 | 37.50] loss=4.48 avg=4.51\n",
      "[29 | 38.56] loss=3.88 avg=4.48\n",
      "[30 | 39.61] loss=4.11 avg=4.47\n",
      "[31 | 40.64] loss=4.31 avg=4.46\n",
      "[32 | 41.68] loss=4.42 avg=4.46\n",
      "[33 | 42.75] loss=4.09 avg=4.45\n",
      "[34 | 43.81] loss=3.80 avg=4.42\n",
      "[35 | 44.84] loss=4.16 avg=4.42\n",
      "[36 | 45.88] loss=4.25 avg=4.41\n",
      "[37 | 46.90] loss=4.07 avg=4.40\n",
      "[38 | 48.01] loss=4.51 avg=4.40\n",
      "[39 | 49.07] loss=3.78 avg=4.38\n",
      "[40 | 50.12] loss=4.03 avg=4.37\n",
      "[41 | 51.15] loss=4.25 avg=4.37\n",
      "[42 | 52.17] loss=4.32 avg=4.37\n",
      "[43 | 53.22] loss=4.33 avg=4.37\n",
      "[44 | 54.30] loss=4.22 avg=4.36\n",
      "[45 | 55.33] loss=3.61 avg=4.34\n",
      "[46 | 56.39] loss=3.77 avg=4.33\n",
      "[47 | 57.50] loss=4.13 avg=4.32\n",
      "[48 | 58.57] loss=4.31 avg=4.32\n",
      "[49 | 59.64] loss=4.13 avg=4.32\n",
      "[50 | 60.70] loss=4.34 avg=4.32\n",
      "[51 | 61.74] loss=4.26 avg=4.32\n",
      "[52 | 62.77] loss=3.79 avg=4.30\n",
      "[53 | 63.81] loss=3.67 avg=4.29\n",
      "[54 | 64.88] loss=3.47 avg=4.27\n",
      "[55 | 65.92] loss=3.52 avg=4.25\n",
      "[56 | 67.00] loss=4.46 avg=4.26\n",
      "[57 | 68.07] loss=3.82 avg=4.25\n",
      "[58 | 69.11] loss=4.15 avg=4.24\n",
      "[59 | 70.18] loss=4.38 avg=4.25\n",
      "[60 | 71.24] loss=4.00 avg=4.24\n",
      "[61 | 72.27] loss=4.20 avg=4.24\n",
      "[62 | 73.30] loss=3.87 avg=4.23\n",
      "[63 | 74.33] loss=3.84 avg=4.22\n",
      "[64 | 75.36] loss=4.20 avg=4.22\n",
      "[65 | 76.40] loss=3.51 avg=4.21\n",
      "[66 | 77.43] loss=3.41 avg=4.19\n",
      "[67 | 78.46] loss=3.86 avg=4.18\n",
      "[68 | 79.49] loss=3.97 avg=4.18\n",
      "[69 | 80.52] loss=4.30 avg=4.18\n",
      "[70 | 81.56] loss=3.30 avg=4.17\n",
      "[71 | 82.59] loss=4.35 avg=4.17\n",
      "[72 | 83.63] loss=4.10 avg=4.17\n",
      "[73 | 84.66] loss=3.69 avg=4.16\n",
      "[74 | 85.70] loss=4.41 avg=4.16\n",
      "[75 | 86.73] loss=4.07 avg=4.16\n",
      "[76 | 87.77] loss=3.82 avg=4.16\n",
      "[77 | 88.80] loss=4.43 avg=4.16\n",
      "[78 | 89.84] loss=4.37 avg=4.16\n",
      "[79 | 90.87] loss=4.22 avg=4.17\n",
      "[80 | 91.91] loss=4.10 avg=4.16\n",
      "[81 | 92.95] loss=4.27 avg=4.17\n",
      "[82 | 93.99] loss=4.42 avg=4.17\n",
      "[83 | 95.02] loss=4.33 avg=4.17\n",
      "[84 | 96.07] loss=4.30 avg=4.18\n",
      "[85 | 97.11] loss=3.94 avg=4.17\n",
      "[86 | 98.15] loss=3.61 avg=4.16\n",
      "[87 | 99.19] loss=4.32 avg=4.16\n",
      "[88 | 100.25] loss=4.30 avg=4.17\n",
      "[89 | 101.31] loss=3.62 avg=4.16\n",
      "[90 | 102.35] loss=4.13 avg=4.16\n",
      "[91 | 103.44] loss=4.38 avg=4.16\n",
      "[92 | 104.50] loss=3.81 avg=4.16\n",
      "[93 | 105.60] loss=3.67 avg=4.15\n",
      "[94 | 106.64] loss=3.97 avg=4.14\n",
      "[95 | 107.69] loss=4.08 avg=4.14\n",
      "[96 | 108.74] loss=3.38 avg=4.13\n",
      "[97 | 109.81] loss=4.36 avg=4.13\n",
      "[98 | 110.89] loss=3.85 avg=4.13\n",
      "[99 | 111.94] loss=4.52 avg=4.14\n",
      "[100 | 112.97] loss=4.30 avg=4.14\n",
      "[101 | 114.00] loss=4.00 avg=4.14\n",
      "[102 | 115.03] loss=3.98 avg=4.13\n",
      "[103 | 116.07] loss=3.41 avg=4.12\n",
      "[104 | 117.10] loss=4.15 avg=4.12\n",
      "[105 | 118.17] loss=3.43 avg=4.11\n",
      "[106 | 119.22] loss=4.33 avg=4.12\n",
      "[107 | 120.28] loss=3.68 avg=4.11\n",
      "[108 | 121.33] loss=4.02 avg=4.11\n",
      "[109 | 122.39] loss=4.12 avg=4.11\n",
      "[110 | 123.44] loss=4.23 avg=4.11\n",
      "[111 | 124.48] loss=3.87 avg=4.11\n",
      "[112 | 125.54] loss=3.45 avg=4.10\n",
      "[113 | 126.59] loss=3.43 avg=4.09\n",
      "[114 | 127.65] loss=4.28 avg=4.09\n",
      "[115 | 128.72] loss=4.32 avg=4.09\n",
      "[116 | 129.79] loss=3.67 avg=4.09\n",
      "[117 | 130.85] loss=4.13 avg=4.09\n",
      "[118 | 131.91] loss=4.41 avg=4.09\n",
      "[119 | 132.99] loss=3.33 avg=4.08\n",
      "[120 | 134.06] loss=3.70 avg=4.08\n",
      "[121 | 135.13] loss=4.19 avg=4.08\n",
      "[122 | 136.19] loss=3.38 avg=4.07\n",
      "[123 | 137.23] loss=3.49 avg=4.06\n",
      "[124 | 138.26] loss=3.46 avg=4.05\n",
      "[125 | 139.30] loss=2.96 avg=4.04\n",
      "[126 | 140.36] loss=4.27 avg=4.04\n",
      "[127 | 141.42] loss=4.02 avg=4.04\n",
      "[128 | 142.45] loss=3.59 avg=4.03\n",
      "[129 | 143.53] loss=4.28 avg=4.04\n",
      "[130 | 144.56] loss=3.19 avg=4.02\n",
      "[131 | 145.59] loss=3.70 avg=4.02\n",
      "[132 | 146.63] loss=2.77 avg=4.00\n",
      "[133 | 147.66] loss=3.79 avg=4.00\n",
      "[134 | 148.70] loss=3.69 avg=4.00\n",
      "[135 | 149.73] loss=2.88 avg=3.98\n",
      "[136 | 150.77] loss=3.51 avg=3.97\n",
      "[137 | 151.82] loss=3.89 avg=3.97\n",
      "[138 | 152.85] loss=4.14 avg=3.98\n",
      "[139 | 153.89] loss=2.72 avg=3.96\n",
      "[140 | 154.93] loss=4.00 avg=3.96\n",
      "[141 | 155.98] loss=3.98 avg=3.96\n",
      "[142 | 157.01] loss=3.10 avg=3.95\n",
      "[143 | 158.05] loss=3.86 avg=3.95\n",
      "[144 | 159.08] loss=4.23 avg=3.95\n",
      "[145 | 160.12] loss=4.35 avg=3.96\n",
      "[146 | 161.15] loss=3.09 avg=3.95\n",
      "[147 | 162.19] loss=3.06 avg=3.93\n",
      "[148 | 163.25] loss=4.30 avg=3.94\n",
      "[149 | 164.29] loss=3.71 avg=3.94\n",
      "[150 | 165.32] loss=2.97 avg=3.92\n",
      "[151 | 166.35] loss=3.64 avg=3.92\n",
      "[152 | 167.39] loss=2.78 avg=3.90\n",
      "[153 | 168.42] loss=4.00 avg=3.91\n",
      "[154 | 169.46] loss=3.62 avg=3.90\n",
      "[155 | 170.50] loss=3.85 avg=3.90\n",
      "[156 | 171.53] loss=4.28 avg=3.91\n",
      "[157 | 172.57] loss=3.45 avg=3.90\n",
      "[158 | 173.64] loss=2.88 avg=3.89\n",
      "[159 | 174.70] loss=3.46 avg=3.88\n",
      "[160 | 175.75] loss=3.11 avg=3.87\n",
      "[161 | 176.80] loss=3.08 avg=3.86\n",
      "[162 | 177.85] loss=3.15 avg=3.85\n",
      "[163 | 178.88] loss=4.28 avg=3.86\n",
      "[164 | 179.92] loss=4.31 avg=3.86\n",
      "[165 | 180.96] loss=2.76 avg=3.85\n",
      "[166 | 181.99] loss=3.48 avg=3.85\n",
      "[167 | 183.03] loss=3.86 avg=3.85\n",
      "[168 | 184.06] loss=3.52 avg=3.84\n",
      "[169 | 185.09] loss=3.90 avg=3.84\n",
      "[170 | 186.13] loss=3.71 avg=3.84\n",
      "[171 | 187.16] loss=2.73 avg=3.83\n",
      "[172 | 188.20] loss=2.89 avg=3.82\n",
      "[173 | 189.23] loss=3.15 avg=3.81\n",
      "[174 | 190.27] loss=4.04 avg=3.81\n",
      "[175 | 191.30] loss=3.87 avg=3.81\n",
      "[176 | 192.33] loss=2.83 avg=3.80\n",
      "[177 | 193.37] loss=2.73 avg=3.79\n",
      "[178 | 194.41] loss=2.73 avg=3.77\n",
      "[179 | 195.45] loss=3.21 avg=3.77\n",
      "[180 | 196.48] loss=3.61 avg=3.77\n",
      "[181 | 197.52] loss=3.30 avg=3.76\n",
      "[182 | 198.55] loss=4.00 avg=3.76\n",
      "[183 | 199.59] loss=3.73 avg=3.76\n",
      "[184 | 200.63] loss=3.63 avg=3.76\n",
      "[185 | 201.66] loss=3.60 avg=3.76\n",
      "[186 | 202.70] loss=4.00 avg=3.76\n",
      "[187 | 203.74] loss=3.68 avg=3.76\n",
      "[188 | 204.78] loss=4.29 avg=3.77\n",
      "[189 | 205.81] loss=3.71 avg=3.77\n",
      "[190 | 206.85] loss=3.47 avg=3.76\n",
      "[191 | 207.89] loss=3.22 avg=3.76\n",
      "[192 | 208.92] loss=2.88 avg=3.75\n",
      "[193 | 209.96] loss=3.38 avg=3.74\n",
      "[194 | 210.99] loss=2.92 avg=3.73\n",
      "[195 | 212.03] loss=3.04 avg=3.72\n",
      "[196 | 213.07] loss=3.50 avg=3.72\n",
      "[197 | 214.10] loss=3.31 avg=3.72\n",
      "[198 | 215.14] loss=3.53 avg=3.72\n",
      "[199 | 216.18] loss=2.40 avg=3.70\n",
      "[200 | 217.21] loss=4.18 avg=3.71\n",
      "======== SAMPLE 1 ========\n",
      " Bone\n",
      "Cannot put items in bin using a \"bring to stockpiles\" command\n",
      "Trident, Short Sword & Dagger, Long Bow & Armor in bin\n",
      "Bins are not working after embark.\n",
      "Crash when looking at (1) inside a cage, (2) outside a cage, (3) in a bin\n",
      "Clone animals not being cloned\n",
      "Skeletal corpse (head, hands, feet, knees) not duplicated in a tomb\n",
      "Nervous dwarf stuck doing nothing for a year.\n",
      "Crash when trying to view an item at a workshop\n",
      "Dwarves won't haul items from the bottom of their bins onto the stockpile\n",
      "Meadow only produces one crop\n",
      "Tame dragons, giant cave spiders, and giant scorpions\n",
      "No message when placing an artifact in a stockpile\n",
      "Mason placed construction with no materials\n",
      "Cannot press any keys to take items from a stockpile\n",
      "Marksdwarves won't get metal smelters to create armor for their weapons.\n",
      "Marksdwarves won't pick up weapons to shoot at targets if they're not actively hostile\n",
      "Crutchless use of the \"z\" key and \"backspace\" to designate the rear views of dwarves while sitting.\n",
      "Birds can fly.\n",
      "Crash on save with [PRINT_MODE:TEXT]\n",
      "Crash upon exit window of Dwarf Mode\n",
      "Seg error during save/load game?\n",
      "Crash upon leaving menu/familiarize with dwarves\n",
      "Crash during world generation, save\n",
      "Game crashes on embark\n",
      "Crash from a corrupted save\n",
      "Crash when starting Dwarf Mode.\n",
      "Crash when saving on rainy days\n",
      "Dwarves will not haul items from the bottom of their bins onto the stockpile.\n",
      "Items in bins are stuck if a dwarf walks past them\n",
      "Crashes on loading world\n",
      "Crash on save (may have crashed my save)\n",
      "Crash from a corrupted save\n",
      "Game crashes on embarking in a world with a \"drown in magma\" result\n",
      "Crash when I exit menu\n",
      "Crash when saving\n",
      "Crash when loading World of legends area\n",
      "Crash on save/load world (may have crashed my save)\n",
      "Crash when calling animal men\n",
      "Crash when loading world with [PRINT_MODE:TEXT]\n",
      "Crash on loading of Dwarf Mode save game\n",
      "Crash when loading a dwarven site\n",
      "Crash when attempting to view/save city landscape in town\n",
      "Crash when loading world (may have crashed this save!)\n",
      "Crash when calling animal men\n",
      "Crashes when I load a saved embark town\n",
      "Crashes when calling animal men.\n",
      "Crash on embark in the wilderness area\n",
      "Crash when starting game to a particular game in a particular generation\n",
      "Dwarves' job description list includes animals that have died of old age\n",
      "Lungfish grow to huge sizes\n",
      "Trained mount can fight off pack animals and non-wild animals\n",
      "Babies born from wedlock (inactive) and with active jobs cannot be removed from parents home by 'take to' actions\n",
      "Inactive and un-healed parents won't place babies in cradle (Cannot breed)\n",
      "Babies born while raising inactive or dead parents are not placed in the next birth order in your history list.\n",
      "Crash when attempting to view dwarves in hospitals\n",
      "Crash when viewing them\n",
      "Crashes when viewing dwarves in hospitals\n",
      "Mud and sand in a mud pit is never generated as material\n",
      "Crash when viewing dwarf in hospital.\n",
      "Crashes when viewing a dwarf in hospital\n",
      "Game crashes when reaching the limit of the player's burrow\n",
      "Hospital beds disappear when removed from wall (under floor/ceiling)\n",
      "Dwarves in hospital bed won't rest.\n",
      "When a dwarf is placed in a hospital bed, he has no room for any other dwarves currently in the game.\n",
      "[KITCHEN] fails to appear!\n",
      "[NECK] Has no effect\n",
      "Adventurer's skull and ribs get crushed and broken when attempting to use the \"Rest\" action\n",
      "Cannot Rest while Slain by a vampire\n",
      "Dwarves not able to feed\n",
      "Tantruming dwarfs won't rest\n",
      "Game Crashes when approaching or visiting a site where vampires live\n",
      "Game Crashes when viewing a creature\n",
      "Crash when viewing corpses of fallen foes\n",
      "Companions do not have the [LEVEL] tag; instead carry items to stockpile\n",
      "Crash on load\n",
      "Game freezes up\n",
      "Climbing generates momentum that cannot be stopped\n",
      "Adventure mode characters are invincible - sometimes \"crash\" when attempting to walk\n",
      "Mud does not cause disease\n",
      "Cannot take food from a stockpile\n",
      "\"Farms\" and \"forest crops\" cannot be planted in zones with grass/wildflowers/taro\n",
      "Inheritance crisis not handled correctly on a couple of fronts\n",
      "Adventure Mode character doesn't get a name\n",
      "Sudden slowdown before anything plays\n",
      "Unable to find path.\n",
      "Inactive vampire still in quest log\n",
      "Crash when using Real Time Tag\n",
      "\"dire gale\" not always a warning of impending \"dire temperature\"\n",
      "\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201 | 241.31] loss=3.08 avg=3.70\n",
      "[202 | 242.43] loss=3.66 avg=3.70\n",
      "[203 | 243.53] loss=3.92 avg=3.70\n",
      "[204 | 244.59] loss=2.15 avg=3.68\n",
      "[205 | 245.66] loss=3.08 avg=3.68\n",
      "[206 | 246.75] loss=3.94 avg=3.68\n",
      "[207 | 247.84] loss=3.92 avg=3.68\n",
      "[208 | 248.90] loss=2.80 avg=3.67\n",
      "[209 | 249.93] loss=3.10 avg=3.66\n",
      "[210 | 250.97] loss=2.71 avg=3.65\n",
      "[211 | 252.07] loss=3.49 avg=3.65\n",
      "[212 | 253.14] loss=3.00 avg=3.64\n",
      "[213 | 254.22] loss=2.82 avg=3.64\n",
      "[214 | 255.25] loss=2.34 avg=3.62\n",
      "[215 | 256.32] loss=3.15 avg=3.62\n",
      "[216 | 257.35] loss=4.08 avg=3.62\n",
      "[217 | 258.43] loss=3.14 avg=3.62\n",
      "[218 | 259.50] loss=2.89 avg=3.61\n",
      "[219 | 260.55] loss=3.77 avg=3.61\n",
      "[220 | 261.60] loss=3.15 avg=3.60\n",
      "[221 | 262.68] loss=2.98 avg=3.60\n",
      "[222 | 263.73] loss=3.09 avg=3.59\n",
      "[223 | 264.81] loss=4.14 avg=3.60\n",
      "[224 | 265.90] loss=2.41 avg=3.58\n",
      "[225 | 266.98] loss=2.33 avg=3.57\n",
      "[226 | 268.07] loss=3.29 avg=3.57\n",
      "[227 | 269.15] loss=2.62 avg=3.56\n",
      "[228 | 270.22] loss=3.60 avg=3.56\n",
      "[229 | 271.25] loss=4.32 avg=3.57\n",
      "[230 | 272.28] loss=3.51 avg=3.56\n",
      "[231 | 273.33] loss=3.29 avg=3.56\n",
      "[232 | 274.36] loss=2.65 avg=3.55\n",
      "[233 | 275.44] loss=3.38 avg=3.55\n",
      "[234 | 276.48] loss=2.40 avg=3.54\n",
      "[235 | 277.51] loss=3.45 avg=3.54\n",
      "[236 | 278.56] loss=3.55 avg=3.54\n",
      "[237 | 279.60] loss=4.54 avg=3.55\n",
      "[238 | 280.65] loss=2.65 avg=3.54\n",
      "[239 | 281.70] loss=2.06 avg=3.52\n",
      "[240 | 282.79] loss=3.29 avg=3.52\n",
      "[241 | 283.82] loss=3.21 avg=3.52\n",
      "[242 | 284.89] loss=3.80 avg=3.52\n",
      "[243 | 285.92] loss=3.58 avg=3.52\n",
      "[244 | 286.95] loss=2.61 avg=3.51\n",
      "[245 | 287.98] loss=3.02 avg=3.50\n",
      "[246 | 289.02] loss=2.77 avg=3.50\n",
      "[247 | 290.05] loss=3.75 avg=3.50\n",
      "[248 | 291.08] loss=2.53 avg=3.49\n",
      "[249 | 292.11] loss=4.42 avg=3.50\n",
      "[250 | 293.15] loss=2.04 avg=3.48\n",
      "[251 | 294.20] loss=3.00 avg=3.48\n",
      "[252 | 295.23] loss=2.97 avg=3.47\n",
      "[253 | 296.30] loss=2.26 avg=3.46\n",
      "[254 | 297.34] loss=1.85 avg=3.44\n",
      "[255 | 298.43] loss=2.97 avg=3.44\n",
      "[256 | 299.51] loss=1.66 avg=3.42\n",
      "[257 | 300.54] loss=1.86 avg=3.40\n",
      "[258 | 301.57] loss=3.09 avg=3.40\n",
      "[259 | 302.61] loss=3.70 avg=3.40\n",
      "[260 | 303.64] loss=2.00 avg=3.38\n",
      "[261 | 304.68] loss=2.87 avg=3.38\n",
      "[262 | 305.72] loss=2.52 avg=3.37\n",
      "[263 | 306.78] loss=1.97 avg=3.35\n",
      "[264 | 307.82] loss=4.70 avg=3.37\n",
      "[265 | 308.86] loss=2.06 avg=3.35\n",
      "[266 | 309.90] loss=2.63 avg=3.35\n",
      "[267 | 310.93] loss=2.79 avg=3.34\n",
      "[268 | 311.96] loss=2.43 avg=3.33\n",
      "[269 | 313.03] loss=2.66 avg=3.32\n",
      "[270 | 314.08] loss=2.62 avg=3.32\n",
      "[271 | 315.12] loss=4.15 avg=3.33\n",
      "[272 | 316.16] loss=2.86 avg=3.32\n",
      "[273 | 317.19] loss=1.84 avg=3.30\n",
      "[274 | 318.24] loss=3.12 avg=3.30\n",
      "[275 | 319.28] loss=2.39 avg=3.29\n",
      "[276 | 320.36] loss=4.07 avg=3.30\n",
      "[277 | 321.52] loss=3.32 avg=3.30\n",
      "[278 | 322.59] loss=3.83 avg=3.31\n",
      "[279 | 323.64] loss=2.81 avg=3.30\n",
      "[280 | 324.67] loss=1.93 avg=3.29\n",
      "[281 | 325.71] loss=3.44 avg=3.29\n",
      "[282 | 326.76] loss=3.40 avg=3.29\n",
      "[283 | 327.84] loss=3.97 avg=3.30\n",
      "[284 | 328.93] loss=3.99 avg=3.30\n",
      "[285 | 329.97] loss=2.13 avg=3.29\n",
      "[286 | 331.02] loss=2.29 avg=3.28\n",
      "[287 | 332.06] loss=3.96 avg=3.29\n",
      "[288 | 333.11] loss=3.92 avg=3.30\n",
      "[289 | 334.14] loss=2.68 avg=3.29\n",
      "[290 | 335.17] loss=2.02 avg=3.28\n",
      "[291 | 336.24] loss=2.71 avg=3.27\n",
      "[292 | 337.28] loss=1.54 avg=3.25\n",
      "[293 | 338.34] loss=1.99 avg=3.24\n",
      "[294 | 339.38] loss=2.75 avg=3.23\n",
      "[295 | 340.41] loss=3.37 avg=3.23\n",
      "[296 | 341.47] loss=4.15 avg=3.24\n",
      "[297 | 342.51] loss=3.64 avg=3.25\n",
      "[298 | 343.58] loss=2.28 avg=3.24\n",
      "[299 | 344.62] loss=3.25 avg=3.24\n",
      "[300 | 345.69] loss=2.55 avg=3.23\n",
      "[301 | 346.76] loss=3.71 avg=3.24\n",
      "[302 | 347.80] loss=1.49 avg=3.22\n",
      "[303 | 348.84] loss=1.72 avg=3.20\n",
      "[304 | 349.88] loss=2.64 avg=3.20\n",
      "[305 | 350.95] loss=2.22 avg=3.19\n",
      "[306 | 351.99] loss=2.15 avg=3.17\n",
      "[307 | 353.03] loss=3.50 avg=3.18\n",
      "[308 | 354.07] loss=2.02 avg=3.17\n",
      "[309 | 355.12] loss=1.63 avg=3.15\n",
      "[310 | 356.18] loss=3.16 avg=3.15\n",
      "[311 | 357.24] loss=2.53 avg=3.14\n",
      "[312 | 358.27] loss=4.72 avg=3.16\n",
      "[313 | 359.32] loss=3.53 avg=3.16\n",
      "[314 | 360.36] loss=2.59 avg=3.16\n",
      "[315 | 361.40] loss=2.19 avg=3.15\n",
      "[316 | 362.47] loss=2.48 avg=3.14\n",
      "[317 | 363.52] loss=3.09 avg=3.14\n",
      "[318 | 364.60] loss=3.33 avg=3.14\n",
      "[319 | 365.65] loss=2.81 avg=3.14\n",
      "[320 | 366.72] loss=2.31 avg=3.13\n",
      "[321 | 367.77] loss=1.48 avg=3.11\n",
      "[322 | 368.81] loss=2.18 avg=3.10\n",
      "[323 | 369.85] loss=4.07 avg=3.11\n",
      "[324 | 370.90] loss=1.99 avg=3.10\n",
      "[325 | 371.96] loss=2.33 avg=3.09\n",
      "[326 | 373.00] loss=1.68 avg=3.08\n",
      "[327 | 374.05] loss=1.98 avg=3.07\n",
      "[328 | 375.09] loss=1.76 avg=3.05\n",
      "[329 | 376.12] loss=2.81 avg=3.05\n",
      "[330 | 377.16] loss=3.62 avg=3.06\n",
      "[331 | 378.20] loss=1.00 avg=3.04\n",
      "[332 | 379.28] loss=1.61 avg=3.02\n",
      "[333 | 380.32] loss=2.05 avg=3.01\n",
      "[334 | 381.36] loss=1.29 avg=2.99\n",
      "[335 | 382.42] loss=2.33 avg=2.99\n",
      "[336 | 383.46] loss=1.03 avg=2.97\n",
      "[337 | 384.51] loss=3.79 avg=2.97\n",
      "[338 | 385.57] loss=1.55 avg=2.96\n",
      "[339 | 386.62] loss=4.94 avg=2.98\n",
      "[340 | 387.66] loss=2.68 avg=2.98\n",
      "[341 | 388.71] loss=3.11 avg=2.98\n",
      "[342 | 389.77] loss=3.79 avg=2.99\n",
      "[343 | 390.80] loss=1.54 avg=2.97\n",
      "[344 | 391.84] loss=1.81 avg=2.96\n",
      "[345 | 392.88] loss=1.65 avg=2.95\n",
      "[346 | 393.98] loss=3.21 avg=2.95\n",
      "[347 | 395.02] loss=2.69 avg=2.95\n",
      "[348 | 396.07] loss=1.55 avg=2.93\n",
      "[349 | 397.12] loss=2.80 avg=2.93\n",
      "[350 | 398.19] loss=2.18 avg=2.92\n",
      "[351 | 399.23] loss=2.33 avg=2.92\n",
      "[352 | 400.27] loss=3.23 avg=2.92\n",
      "[353 | 401.33] loss=1.14 avg=2.90\n",
      "[354 | 402.37] loss=2.73 avg=2.90\n",
      "[355 | 403.44] loss=1.87 avg=2.89\n",
      "[356 | 404.48] loss=2.11 avg=2.88\n",
      "[357 | 405.51] loss=2.85 avg=2.88\n",
      "[358 | 406.55] loss=1.96 avg=2.87\n",
      "[359 | 407.59] loss=1.66 avg=2.86\n",
      "[360 | 408.64] loss=2.40 avg=2.85\n",
      "[361 | 409.68] loss=2.33 avg=2.85\n",
      "[362 | 410.72] loss=0.87 avg=2.83\n",
      "[363 | 411.79] loss=4.88 avg=2.85\n",
      "[364 | 412.83] loss=4.93 avg=2.87\n",
      "[365 | 413.87] loss=2.22 avg=2.86\n",
      "[366 | 414.91] loss=1.09 avg=2.85\n",
      "[367 | 415.96] loss=3.52 avg=2.85\n",
      "[368 | 417.01] loss=2.01 avg=2.84\n",
      "[369 | 418.07] loss=2.43 avg=2.84\n",
      "[370 | 419.16] loss=3.61 avg=2.85\n",
      "[371 | 420.20] loss=3.25 avg=2.85\n",
      "[372 | 421.24] loss=1.94 avg=2.84\n",
      "[373 | 422.28] loss=1.79 avg=2.83\n",
      "[374 | 423.35] loss=3.58 avg=2.84\n",
      "[375 | 424.39] loss=3.21 avg=2.84\n",
      "[376 | 425.45] loss=3.93 avg=2.85\n",
      "[377 | 426.53] loss=3.07 avg=2.86\n",
      "[378 | 427.59] loss=1.94 avg=2.85\n",
      "[379 | 428.71] loss=3.04 avg=2.85\n",
      "[380 | 429.82] loss=2.78 avg=2.85\n",
      "[381 | 430.92] loss=1.23 avg=2.83\n",
      "[382 | 432.01] loss=2.24 avg=2.83\n",
      "[383 | 433.09] loss=2.12 avg=2.82\n",
      "[384 | 434.15] loss=1.17 avg=2.80\n",
      "[385 | 435.21] loss=2.56 avg=2.80\n",
      "[386 | 436.25] loss=2.75 avg=2.80\n",
      "[387 | 437.30] loss=2.94 avg=2.80\n",
      "[388 | 438.38] loss=2.43 avg=2.80\n",
      "[389 | 439.45] loss=1.46 avg=2.78\n",
      "[390 | 440.48] loss=3.20 avg=2.79\n",
      "[391 | 441.59] loss=2.10 avg=2.78\n",
      "[392 | 442.68] loss=1.93 avg=2.77\n",
      "[393 | 443.80] loss=2.13 avg=2.77\n",
      "[394 | 444.87] loss=4.32 avg=2.78\n",
      "[395 | 445.93] loss=2.24 avg=2.78\n",
      "[396 | 446.97] loss=0.97 avg=2.76\n",
      "[397 | 448.01] loss=1.47 avg=2.74\n",
      "[398 | 449.11] loss=3.30 avg=2.75\n",
      "[399 | 450.21] loss=1.96 avg=2.74\n",
      "[400 | 451.27] loss=3.76 avg=2.75\n",
      "======== SAMPLE 1 ========\n",
      " to stop receiving notifications:\n",
      "The tooltip for blast (arrow) causes the game to lock up and crash\n",
      "Game crashes on 'reclaim' or 'defend' defending city\n",
      "Game hangs/freezes on 'eating' dairy in Arena (or 'processing' milker request)\n",
      "Reclaim - Entrance blocked\n",
      "No dwarves hostile to magma in world gen, savegame load causes crash\n",
      "Crash when greeting visitors/retiring adventurer.\n",
      "Dwarves will never, ever, ever butcher some corpse\n",
      "caged goblins can attack visitor/retire.\n",
      "Visitors don't bring milk\n",
      "Crash when dwarf escorts corpse back to tomb\n",
      "Dwarves get stuck \"Transporting ... More\"\n",
      "Crash after 'prepare food', dwarf escorts loaded food to depot\n",
      "Dwarves get stuck \"Loading Recipe Book ...\"\n",
      "Visitors/retire blocked\n",
      "Visitor/Retire blocked by construction\n",
      "Visiting the Tomb of a Mummy prevents retrieval of visited corpses\n",
      "Game crashes then froze when a Mummy dies\n",
      "Visiting the Tomb of a Mummy.\n",
      "Visiting the tomb of a different dwarf repeatedly results in a \"Cannot find path\" error\n",
      "Naming a unit with name space followed by a number inserts an M4 magenta box with a Wadding Pattern:\n",
      "Wagon dragging, digging, sleeping, resume play\n",
      "Retired fortress doesn't have access to stockpile links\n",
      "Crash when greeting necromancer adventurer over banquet hall trap\n",
      "Crash after greeting necromancer\n",
      "Tomb filled with unclaimed corpses. No sign of the merfolk my companions claimed\n",
      "Crash after Reclaim (Dwarf Fortress Mode)\n",
      "Crashes after a few weeks\n",
      "Crash After Reclaim\n",
      "Crashes Upon Retire\n",
      "crash when approaching a goblin slabs.\n",
      "Dwarf mode crashing on embark\n",
      "Wagons cannot reach required stockpiles, blocking wagon access\n",
      "Dwarves will not haul hauled items from an unattended stockpile\n",
      "Hauled wheelbarrows assigned to multiple stockpiles act strangely\n",
      "No Trade Depot\n",
      "When a dwarf hauls an item from a stockpile, the haulers do not have their work order enabled for that dwarf\n",
      "Merchant wagons stuck\n",
      "Dwarves hauling farm plots through water\n",
      "Cannot remove pond compaction\n",
      "Brawling results in \"You insult my intelligence\" being displayed at random on screen\n",
      "Retired fort has hostile undead and demons\n",
      "Worldgen Cities Make No Attempts At Replacing Disappeared as \"Unable to reach site\" despite site being available and available to non-existant species\n",
      "Visitors not resting or sleeping in Fortress Mode.\n",
      "Non-farmable plants in Fortress Mode\n",
      "Dwarf cancels Rest: Cannot Reach Site: Cannot reach site.\n",
      "Crash on embark in single player\n",
      "Wagons teleport/borrow/eat/etc. when available site tiles removed.\n",
      "Campfire zones too small for farm plot\n",
      "Dwarves drag barrels (bought wood?) from depot to barrel stockpile, then unfetter crash\n",
      "Crashes during worldgen when attempting save.\n",
      "Saves crash\n",
      "Cannot bring cups (brewing) and kegs (brewing, keg)\n",
      "No dwarves claim bedrooms\n",
      "Crash when attempting to claim a bed in dorm\n",
      "Incorrect capitalization in Report Entry for Negative Value Input\n",
      "Incorrect Altar Keeps\n",
      "Lever functions incorrectly in some dialog\n",
      "Cannot use \"Cancel as Ctrl\" or \"Cancel As Key\" to assign the character to a specific key.\n",
      "Game crashes when reporting negative value on item hoarding dwarf.\n",
      "Crash when reporting negative val. on caravan goods\n",
      "Crash after reporting negative val. on caravan trade\n",
      "Crash when reporting negative value on caravan goods\n",
      "Items with [BONECARN] in parenthetical, self-explanatory names are not generated in the world gen chamber.\n",
      "Crash upon reporting negative val. on caravan goods\n",
      "Game hangs/cancels Attempting to report negative value on caravan cargo\n",
      "Upon attempting to report negative val. on caravan goods, the game crashes.\n",
      "On caravan wagons returning to depot, game hangs\n",
      "Bins/Bins/Breakers breaking\n",
      "Stairs/ramps leading directly to lava channel\n",
      "Bin/broker traded to Trading Depot\n",
      "Caravan comes to depot,  doesn't trade,  then the  traders proceed to do it.\n",
      "cancels Asking Wagon to a Depot \"Cancels seek depot, refuse to locate depot.\"\n",
      "cancels Asking Wagon to a Depot \"No traders trading, aborting ask.\"\n",
      "cancels Asking Wagon to a Depot: Needs Repair\n",
      "Cannot ask for directions to the depot from the visitor info and need only ask the dwarf about the dwarf and his caravan\n",
      "Visitor and caravan success rate is wrong (generously)\n",
      "Cannot request specific animal by name\n",
      "Sends unmade obsidian long/short/up/down/left/right tubes.\n",
      "Dwarf will not claim workshop\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[401 | 472.39] loss=1.58 avg=2.74\n",
      "[402 | 473.44] loss=1.61 avg=2.73\n",
      "[403 | 474.48] loss=3.28 avg=2.73\n",
      "[404 | 475.51] loss=1.61 avg=2.72\n",
      "[405 | 476.59] loss=1.13 avg=2.71\n",
      "[406 | 477.69] loss=2.59 avg=2.71\n",
      "[407 | 478.81] loss=2.09 avg=2.70\n",
      "[408 | 479.85] loss=0.75 avg=2.68\n",
      "[409 | 480.89] loss=3.74 avg=2.69\n",
      "[410 | 481.94] loss=3.12 avg=2.69\n",
      "[411 | 482.97] loss=2.06 avg=2.69\n",
      "[412 | 484.06] loss=1.23 avg=2.67\n",
      "[413 | 485.12] loss=2.19 avg=2.67\n",
      "[414 | 486.23] loss=2.07 avg=2.66\n",
      "[415 | 487.34] loss=3.02 avg=2.67\n",
      "[416 | 488.39] loss=3.35 avg=2.67\n",
      "[417 | 489.43] loss=3.81 avg=2.68\n",
      "[418 | 490.46] loss=2.12 avg=2.68\n",
      "[419 | 491.50] loss=1.24 avg=2.66\n",
      "[420 | 492.54] loss=2.44 avg=2.66\n",
      "[421 | 493.60] loss=3.22 avg=2.67\n",
      "[422 | 494.63] loss=2.39 avg=2.66\n",
      "[423 | 495.66] loss=2.10 avg=2.66\n",
      "[424 | 496.71] loss=1.81 avg=2.65\n",
      "[425 | 497.77] loss=1.45 avg=2.64\n",
      "[426 | 498.84] loss=2.78 avg=2.64\n",
      "[427 | 499.91] loss=1.83 avg=2.63\n",
      "[428 | 500.95] loss=1.51 avg=2.62\n",
      "[429 | 502.03] loss=0.74 avg=2.60\n",
      "[430 | 503.07] loss=2.11 avg=2.60\n",
      "[431 | 504.11] loss=1.47 avg=2.58\n",
      "[432 | 505.15] loss=1.03 avg=2.57\n",
      "[433 | 506.19] loss=1.96 avg=2.56\n",
      "[434 | 507.25] loss=1.83 avg=2.56\n",
      "[435 | 508.31] loss=2.58 avg=2.56\n",
      "[436 | 509.36] loss=4.12 avg=2.57\n",
      "[437 | 510.41] loss=1.86 avg=2.56\n",
      "[438 | 511.46] loss=3.83 avg=2.58\n",
      "[439 | 512.52] loss=2.25 avg=2.57\n",
      "[440 | 513.61] loss=2.67 avg=2.57\n",
      "[441 | 514.71] loss=2.63 avg=2.57\n",
      "[442 | 515.80] loss=2.80 avg=2.58\n",
      "[443 | 516.90] loss=2.53 avg=2.58\n",
      "[444 | 517.98] loss=2.53 avg=2.58\n",
      "[445 | 519.04] loss=1.38 avg=2.56\n",
      "[446 | 520.10] loss=2.97 avg=2.57\n",
      "[447 | 521.18] loss=1.23 avg=2.55\n",
      "[448 | 522.23] loss=1.19 avg=2.54\n",
      "[449 | 523.29] loss=3.42 avg=2.55\n",
      "[450 | 524.37] loss=2.64 avg=2.55\n",
      "[451 | 525.47] loss=2.82 avg=2.55\n",
      "[452 | 526.53] loss=1.44 avg=2.54\n",
      "[453 | 527.63] loss=3.69 avg=2.55\n",
      "[454 | 528.69] loss=2.10 avg=2.55\n",
      "[455 | 529.79] loss=2.86 avg=2.55\n",
      "[456 | 530.88] loss=2.06 avg=2.55\n",
      "[457 | 531.99] loss=1.02 avg=2.53\n",
      "[458 | 533.06] loss=1.82 avg=2.52\n",
      "[459 | 534.15] loss=2.44 avg=2.52\n",
      "[460 | 535.23] loss=1.75 avg=2.52\n",
      "[461 | 536.28] loss=2.88 avg=2.52\n",
      "[462 | 537.33] loss=4.56 avg=2.54\n",
      "[463 | 538.39] loss=3.28 avg=2.55\n",
      "[464 | 539.49] loss=2.19 avg=2.54\n",
      "[465 | 540.53] loss=2.91 avg=2.55\n",
      "[466 | 541.57] loss=1.48 avg=2.54\n",
      "[467 | 542.66] loss=2.28 avg=2.53\n",
      "[468 | 543.70] loss=1.11 avg=2.52\n",
      "[469 | 544.74] loss=0.96 avg=2.50\n",
      "[470 | 545.80] loss=2.13 avg=2.50\n",
      "[471 | 546.88] loss=1.66 avg=2.49\n",
      "[472 | 547.95] loss=3.86 avg=2.51\n",
      "[473 | 549.02] loss=2.09 avg=2.50\n",
      "[474 | 550.08] loss=1.58 avg=2.49\n",
      "[475 | 551.13] loss=1.25 avg=2.48\n",
      "[476 | 552.17] loss=1.42 avg=2.47\n",
      "[477 | 553.25] loss=1.53 avg=2.46\n",
      "[478 | 554.30] loss=1.39 avg=2.45\n",
      "[479 | 555.37] loss=2.48 avg=2.45\n",
      "[480 | 556.44] loss=1.03 avg=2.43\n",
      "[481 | 557.47] loss=2.39 avg=2.43\n",
      "[482 | 558.55] loss=1.44 avg=2.42\n",
      "[483 | 559.63] loss=1.46 avg=2.41\n",
      "[484 | 560.71] loss=1.14 avg=2.40\n",
      "[485 | 561.80] loss=2.28 avg=2.40\n",
      "[486 | 562.87] loss=1.36 avg=2.39\n",
      "[487 | 563.94] loss=1.03 avg=2.38\n",
      "[488 | 565.01] loss=1.78 avg=2.37\n",
      "[489 | 566.08] loss=1.15 avg=2.36\n",
      "[490 | 567.14] loss=2.06 avg=2.35\n",
      "[491 | 568.19] loss=1.57 avg=2.35\n",
      "[492 | 569.26] loss=0.97 avg=2.33\n",
      "[493 | 570.30] loss=2.14 avg=2.33\n",
      "[494 | 571.37] loss=2.14 avg=2.33\n",
      "[495 | 572.44] loss=1.65 avg=2.32\n",
      "[496 | 573.53] loss=2.29 avg=2.32\n",
      "[497 | 574.60] loss=0.67 avg=2.31\n",
      "[498 | 575.67] loss=2.06 avg=2.30\n",
      "[499 | 576.73] loss=1.34 avg=2.29\n",
      "[500 | 577.77] loss=3.62 avg=2.31\n",
      "[501 | 578.87] loss=0.72 avg=2.29\n",
      "[502 | 579.93] loss=1.20 avg=2.28\n",
      "[503 | 581.02] loss=1.93 avg=2.28\n",
      "[504 | 582.10] loss=1.53 avg=2.27\n",
      "[505 | 583.16] loss=0.75 avg=2.25\n",
      "[506 | 584.22] loss=1.39 avg=2.24\n",
      "[507 | 585.30] loss=1.73 avg=2.24\n",
      "[508 | 586.35] loss=1.46 avg=2.23\n",
      "[509 | 587.39] loss=0.84 avg=2.22\n",
      "[510 | 588.42] loss=0.95 avg=2.21\n",
      "[511 | 589.50] loss=0.88 avg=2.19\n",
      "[512 | 590.58] loss=2.25 avg=2.19\n",
      "[513 | 591.62] loss=1.26 avg=2.18\n",
      "[514 | 592.67] loss=2.22 avg=2.18\n",
      "[515 | 593.72] loss=2.24 avg=2.18\n",
      "[516 | 594.86] loss=2.51 avg=2.19\n",
      "[517 | 595.97] loss=1.04 avg=2.18\n",
      "[518 | 597.09] loss=2.57 avg=2.18\n",
      "[519 | 598.14] loss=1.85 avg=2.18\n",
      "[520 | 599.23] loss=0.49 avg=2.16\n",
      "[521 | 600.31] loss=1.15 avg=2.15\n",
      "[522 | 601.40] loss=1.11 avg=2.14\n",
      "[523 | 602.45] loss=1.96 avg=2.14\n",
      "[524 | 603.52] loss=2.15 avg=2.14\n",
      "[525 | 604.63] loss=1.44 avg=2.13\n",
      "[526 | 605.76] loss=1.25 avg=2.12\n",
      "[527 | 606.83] loss=1.90 avg=2.12\n",
      "[528 | 607.88] loss=3.49 avg=2.13\n",
      "[529 | 608.93] loss=1.13 avg=2.12\n",
      "[530 | 609.97] loss=1.95 avg=2.12\n",
      "[531 | 611.01] loss=0.90 avg=2.11\n",
      "[532 | 612.12] loss=2.50 avg=2.11\n",
      "[533 | 613.26] loss=0.67 avg=2.10\n",
      "[534 | 614.37] loss=1.08 avg=2.09\n",
      "[535 | 615.50] loss=1.75 avg=2.08\n",
      "[536 | 616.59] loss=0.77 avg=2.07\n",
      "[537 | 617.69] loss=2.04 avg=2.07\n",
      "[538 | 618.80] loss=0.59 avg=2.06\n",
      "[539 | 619.92] loss=0.89 avg=2.04\n",
      "[540 | 620.96] loss=0.63 avg=2.03\n",
      "[541 | 622.05] loss=2.48 avg=2.03\n",
      "[542 | 623.11] loss=0.80 avg=2.02\n",
      "[543 | 624.17] loss=3.18 avg=2.03\n",
      "[544 | 625.22] loss=1.71 avg=2.03\n",
      "[545 | 626.27] loss=0.85 avg=2.02\n",
      "[546 | 627.34] loss=2.62 avg=2.02\n",
      "[547 | 628.41] loss=1.43 avg=2.02\n",
      "[548 | 629.45] loss=2.04 avg=2.02\n",
      "[549 | 630.49] loss=0.75 avg=2.01\n",
      "[550 | 631.52] loss=1.17 avg=2.00\n",
      "[551 | 632.57] loss=1.18 avg=1.99\n",
      "[552 | 633.61] loss=0.83 avg=1.98\n",
      "[553 | 634.68] loss=1.82 avg=1.98\n",
      "[554 | 635.74] loss=2.21 avg=1.98\n",
      "[555 | 636.78] loss=2.11 avg=1.98\n",
      "[556 | 637.82] loss=0.69 avg=1.97\n",
      "[557 | 638.92] loss=1.00 avg=1.96\n",
      "[558 | 639.96] loss=0.50 avg=1.94\n",
      "[559 | 640.99] loss=0.87 avg=1.93\n",
      "[560 | 642.09] loss=1.06 avg=1.92\n",
      "[561 | 643.16] loss=0.90 avg=1.91\n",
      "[562 | 644.26] loss=1.98 avg=1.91\n",
      "[563 | 645.31] loss=1.18 avg=1.91\n",
      "[564 | 646.41] loss=1.22 avg=1.90\n",
      "[565 | 647.46] loss=1.13 avg=1.89\n",
      "[566 | 648.55] loss=3.85 avg=1.91\n",
      "[567 | 649.68] loss=0.79 avg=1.90\n",
      "[568 | 650.80] loss=2.15 avg=1.90\n",
      "[569 | 651.87] loss=1.18 avg=1.90\n",
      "[570 | 652.91] loss=2.01 avg=1.90\n",
      "[571 | 653.95] loss=1.70 avg=1.89\n",
      "[572 | 655.00] loss=1.36 avg=1.89\n",
      "[573 | 656.05] loss=0.70 avg=1.88\n",
      "[574 | 657.10] loss=0.59 avg=1.86\n",
      "[575 | 658.17] loss=0.65 avg=1.85\n",
      "[576 | 659.26] loss=0.96 avg=1.84\n",
      "[577 | 660.33] loss=1.66 avg=1.84\n",
      "[578 | 661.36] loss=0.62 avg=1.83\n",
      "[579 | 662.41] loss=1.28 avg=1.82\n",
      "[580 | 663.54] loss=1.74 avg=1.82\n",
      "[581 | 664.58] loss=1.40 avg=1.82\n",
      "[582 | 665.62] loss=1.23 avg=1.81\n",
      "[583 | 666.66] loss=0.60 avg=1.80\n",
      "[584 | 667.70] loss=2.08 avg=1.80\n",
      "[585 | 668.74] loss=0.46 avg=1.79\n",
      "[586 | 669.79] loss=0.84 avg=1.78\n",
      "[587 | 670.87] loss=1.67 avg=1.78\n",
      "[588 | 671.97] loss=0.72 avg=1.77\n",
      "[589 | 673.03] loss=2.20 avg=1.77\n",
      "[590 | 674.12] loss=1.73 avg=1.77\n",
      "[591 | 675.23] loss=0.59 avg=1.76\n",
      "[592 | 676.36] loss=3.25 avg=1.78\n",
      "[593 | 677.48] loss=0.79 avg=1.77\n",
      "[594 | 678.53] loss=1.06 avg=1.76\n",
      "[595 | 679.64] loss=1.16 avg=1.75\n",
      "[596 | 680.73] loss=0.89 avg=1.74\n",
      "[597 | 681.79] loss=1.38 avg=1.74\n",
      "[598 | 682.84] loss=1.43 avg=1.74\n",
      "[599 | 683.89] loss=0.60 avg=1.73\n",
      "[600 | 684.98] loss=2.49 avg=1.73\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess, 'bugs.txt', model_name=model_name, steps=1000, restore_from='fresh', sample_every=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate with our fine-tuned language model. We'll look for 1,000 samples of up to 100 tokens, and gpt-2 allows us to run batches in parallel. The generation is non-deterministic (check here for an explanation of why that is https://huggingface.co/blog/how-to-generate), so we won't get the same results at each run time. I've pumped up the temperature (the likelihood of low_probability words being included in our sequences) to get slightly crazier results, which I find amusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = gpt2.generate(sess, length=100, nsamples=1000, batch_size=10, temperature=1.0, top_p=0.9, return_as_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a couple of problems we need to fix before saving our results. The model will generate a chunk of text up to the desired token length, but we want a nice separated list of potential messages. So, we split the sequence on newline characters, throwing away any blank results. Then, we get rid of the last result. Why? Because once the token limit is reached, generation will stop in the middle of a phrase, which we don't want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_texts.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for text in texts:\n",
    "        split_texts = [i for i in text.split('\\n') if len(i) > 0][:-1]\n",
    "        for msg in split_texts:\n",
    "            writer.writerow([msg])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dorf_bugs",
   "language": "python",
   "name": "dorf_bugs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
